---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: open-webui
  namespace: flux-system
  labels:
    reconcile.fluxcd.io/watch: Enabled
spec:
  interval: 15m
  timeout: 5m
  chart:
    spec:
      chart: open-webui
      version: 8.19.x
      sourceRef:
        kind: HelmRepository
        name: open-webui
      interval: 5m
  releaseName: open-webui
  targetNamespace: open-webui
  install:
    createNamespace: true
    remediation:
      retries: 3
  upgrade:
    remediation:
      retries: 3
  test:
    enable: true
  driftDetection:
    mode: enabled
    ignore:
      - paths: [/spec/replicas]
        target:
          kind: Deployment
  values:
    ingress:
      enabled: true
      class: traefik
      annotations:
        cert-manager.io/cluster-issuer: zerossl-production
        traefik.ingress.kubernetes.io/router.entrypoints: websecure
      host: open-webui.sakul-flee.de
      resourceRootUrl: open-webui.sakul-flee.de
      tls: true
      managedCertificate:
        enabled: true
        name: open-webui-sakul-flee-de-tls
        domains:
          - open-webui.sakul-flee.de
    # Only smaller models can run on our cluster, but that should be fine ...
    # even if slow. For anything more complex we'll have to use something like
    # OpenRouter or enlist our PC as an Ollama host. Especially for file parsing
    # models and similar use cases this should work!
    ollama:
      enabled: true
      pipelines:
        enabled: true
      tika:
        enabled: true
    persistence:
      enabled: true
      storageClass: longhorn-replicated
      size: 8Gi
